<oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.openarchives.org/OAI/2.0/" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Text-Attentional Convolutional Neural Networks for Scene Text Detection</dc:title>
 <dc:creator>He, Tong</dc:creator>
 <dc:creator>Huang, Weilin</dc:creator>
 <dc:creator>Qiao, Yu</dc:creator>
 <dc:creator>Yao, Jian</dc:creator>
 <dc:subject>Computer Science - Computer Vision and Pattern Recognition</dc:subject>
 <dc:description>  Recent deep learning models have demonstrated strong capabilities for
classifying text and non-text components in natural images. They extract a
high-level feature computed globally from a whole image component (patch),
where the cluttered background information may dominate true text features in
the deep representation. This leads to less discriminative power and poorer
robustness. In this work, we present a new system for scene text detection by
proposing a novel Text-Attentional Convolutional Neural Network (Text-CNN) that
particularly focuses on extracting text-related regions and features from the
image components. We develop a new learning mechanism to train the Text-CNN
with multi-level and rich supervised information, including text region mask,
character label, and binary text/nontext information. The rich supervision
information enables the Text-CNN with a strong capability for discriminating
ambiguous texts, and also increases its robustness against complicated
background components. The training process is formulated as a multi-task
learning problem, where low-level supervised information greatly facilitates
main task of text/non-text classification. In addition, a powerful low-level
detector called Contrast- Enhancement Maximally Stable Extremal Regions
(CE-MSERs) is developed, which extends the widely-used MSERs by enhancing
intensity contrast between text patterns and background. This allows it to
detect highly challenging text patterns, resulting in a higher recall. Our
approach achieved promising results on the ICDAR 2013 dataset, with a F-measure
of 0.82, improving the state-of-the-art results substantially.
</dc:description>
 <dc:description>Comment: To appear in IEEE Trans. on Image Processing, 2016</dc:description>
 <dc:date>2015-10-12</dc:date>
 <dc:date>2016-03-24</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1510.03283</dc:identifier>
 <dc:identifier>doi:10.1109/TIP.2016.2547588</dc:identifier>
 </oai_dc:dc>


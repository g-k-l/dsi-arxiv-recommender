<oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.openarchives.org/OAI/2.0/" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Entropy and thinning of discrete random variables</dc:title>
 <dc:creator>Johnson, Oliver</dc:creator>
 <dc:subject>Mathematics - Probability</dc:subject>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We describe five types of results concerning information and concentration of
discrete random variables, and relationships between them, motivated by their
counterparts in the continuous case. The results we consider are information
theoretic approaches to Poisson approximation, the maximum entropy property of
the Poisson distribution, discrete concentration (Poincar\'{e} and logarithmic
Sobolev) inequalities, monotonicity of entropy and concavity of entropy in the
Shepp--Olkin regime.
</dc:description>
 <dc:description>Comment: Draft for Proceedings of IMA theme year in Discrete Structures</dc:description>
 <dc:date>2015-10-19</dc:date>
 <dc:date>2016-06-07</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1510.05390</dc:identifier>
 </oai_dc:dc>


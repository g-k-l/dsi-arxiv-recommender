<oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.openarchives.org/OAI/2.0/" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bounds on Variance for Symmetric Unimodal Distributions</dc:title>
 <dc:creator>Chung, Hye Won</dc:creator>
 <dc:creator>Sadler, Brian M.</dc:creator>
 <dc:creator>Hero, Alfred O.</dc:creator>
 <dc:subject>Computer Science - Information Theory</dc:subject>
 <dc:description>  We show a direct relationship between the variance and the differential
entropy for subclasses of symmetric unimodal distributions by providing an
upper bound on variance in terms of entropy power. Combining this bound with
the well-known entropy power lower bound on variance, we prove that the
variance of the appropriate subclasses of symmetric unimodal distributions can
be bounded below and above by the scaled entropy power. As differential entropy
decreases, the variance is sandwiched between two exponentially decreasing
functions in the differential entropy. This establishes that for the subclasses
of symmetric unimodal distributions, the differential entropy can be used as a
surrogate for concentration of the distribution.
</dc:description>
 <dc:description>Comment: 21 pages, 3 figures</dc:description>
 <dc:date>2015-10-28</dc:date>
 <dc:date>2016-07-06</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1510.08341</dc:identifier>
 </oai_dc:dc>


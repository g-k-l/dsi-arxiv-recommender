<oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.openarchives.org/OAI/2.0/" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Submodularity in Statistics: Comparing the Success of Model Selection
  Methods</dc:title>
 <dc:creator>Johnson, Kory D.</dc:creator>
 <dc:creator>Stine, Robert A.</dc:creator>
 <dc:creator>Foster, Dean P.</dc:creator>
 <dc:subject>Mathematics - Statistics Theory</dc:subject>
 <dc:description>  We demonstrate the usefulness of submodularity in statistics as a
characterization of the difficulty of the \emph{search} problem of feature
selection. The search problem is the ability of a procedure to identify an
informative set of features as opposed to the performance of the optimal set of
features. Submodularity arises naturally in this setting due to its connection
to combinatorial optimization. In statistics, submodularity isolates cases in
which collinearity makes the choice of model features difficult from those in
which this task is routine. Researchers often report the signal-to-noise ratio
to measure the difficulty of simulated data examples. A measure of
submodularity should also be provided as it characterizes an independent
component difficulty. Furthermore, it is closely related to other statistical
assumptions used in the development of the Lasso, Dantzig selector, and sure
information screening.
</dc:description>
 <dc:date>2015-10-21</dc:date>
 <dc:date>2016-05-13</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1510.06301</dc:identifier>
 </oai_dc:dc>


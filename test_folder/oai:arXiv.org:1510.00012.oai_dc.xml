<oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.openarchives.org/OAI/2.0/" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Fast Discrete Distribution Clustering Using Wasserstein Barycenter with
  Sparse Support</dc:title>
 <dc:creator>Ye, Jianbo</dc:creator>
 <dc:creator>Wu, Panruo</dc:creator>
 <dc:creator>Wang, James Z.</dc:creator>
 <dc:creator>Li, Jia</dc:creator>
 <dc:subject>Statistics - Computation</dc:subject>
 <dc:subject>Computer Science - Learning</dc:subject>
 <dc:subject>Statistics - Machine Learning</dc:subject>
 <dc:description>  In a variety of research areas, the bag of weighted vectors and the histogram
are widely used descriptors for complex objects. Both can be expressed as
discrete distributions. D2-clustering pursues the minimum total within-cluster
variation for a set of discrete distributions subject to the
Kantorovich-Wasserstein metric. D2-clustering has a severe scalability issue,
the bottleneck being the computation of a centroid distribution, called
Wasserstein barycenter, that minimizes its sum of squared distances to the
cluster members. In this paper, we develop a modified Bregman ADMM approach for
computing the approximate discrete Wasserstein barycenter of large clusters. In
the case when the support points of the barycenters are unknown and of low
cardinality, our method achieves high accuracy empirically at a much reduced
computational cost. The strengths and weaknesses of our method and its
alternatives are examined through experiments; and scenarios for their
respective usage are recommended. Moreover, we develop both serial and
parallelized versions of the algorithm. By experimenting with large-scale data,
we demonstrate the computational efficiency of the new methods and investigate
their convergence properties and numerical stability. The clustering results
obtained on several datasets in different domains are highly competitive in
comparison with some widely used methods' in the corresponding areas.
</dc:description>
 <dc:description>Comment: double-column, 14 pages, 3 figures, 5 tables</dc:description>
 <dc:date>2015-09-30</dc:date>
 <dc:date>2016-05-08</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1510.00012</dc:identifier>
 </oai_dc:dc>


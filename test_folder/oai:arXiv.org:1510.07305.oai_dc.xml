<oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.openarchives.org/OAI/2.0/" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Parametrized measure models</dc:title>
 <dc:creator>Ay, Nihat</dc:creator>
 <dc:creator>Jost, J&#252;rgen</dc:creator>
 <dc:creator>L&#234;, H&#244;ng V&#226;n</dc:creator>
 <dc:creator>Schwachh&#246;fer, Lorenz</dc:creator>
 <dc:subject>Mathematics - Differential Geometry</dc:subject>
 <dc:subject>53C99, 62B05</dc:subject>
 <dc:description>  We develope a new and general notion of parametric measure models and
statistical models on an arbitrary sample space $\Omega$ which does not assume
that all measures of the model have the same null sets. This is given by a
diffferentiable map from the parameter manifold $M$ into the set of finite
measures or probability measures on $\Omega$, respectively, which is
differentiable when regarded as a map into the Banach space of all signed
measures on $\Omega$. Furthermore, we also give a rigorous definition of roots
of measures and give a natural definition of the Fisher metric and the
Amari-Chentsov tensor as the pullback of tensors defined on the space of roots
of measures. We show that many features such as the preservation of this tensor
under sufficient statistics and the monotonicity formula hold even in this very
general set-up.
</dc:description>
 <dc:description>Comment: 29 pages, revised version, added definition of information loss of
  arbitrary order</dc:description>
 <dc:date>2015-10-25</dc:date>
 <dc:date>2016-04-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1510.07305</dc:identifier>
 </oai_dc:dc>


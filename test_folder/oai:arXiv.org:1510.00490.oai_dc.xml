<oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.openarchives.org/OAI/2.0/" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>On the rate analysis of inexact augmented Lagrangian schemes for convex
  optimization problems with misspecified constraints</dc:title>
 <dc:creator>Ahmadi, H.</dc:creator>
 <dc:creator>Aybat, N. S.</dc:creator>
 <dc:creator>Shanbhag, U. V.</dc:creator>
 <dc:subject>Mathematics - Optimization and Control</dc:subject>
 <dc:description>  We consider a misspecified optimization problem that requires minimizing of a
convex function $f(x;\theta^*)$ in x over a constraint set represented by
$h(x;\theta^*)\leq 0$, where $\theta^*$ is an unknown (or misspecified) vector
of parameters. Suppose $\theta^*$ can be learnt by a distinct process that
generates a sequence of estimators $\theta_k$, each of which is an increasingly
accurate approximation of $\theta^*$. We develop a first-order augmented
Lagrangian scheme for computing an optimal solution $x^*$ while simultaneously
learning $\theta^*$.
</dc:description>
 <dc:description>Comment: For the extended journal version of this preliminary work, see
  arXiv:1608.01879 [math.OC]</dc:description>
 <dc:date>2015-10-02</dc:date>
 <dc:date>2016-08-16</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1510.00490</dc:identifier>
 <dc:identifier>2016 American Control Conference (ACC), Boston, MA, USA, 2016, pp.
  4841-4846</dc:identifier>
 <dc:identifier>doi:10.1109/ACC.2016.7526119</dc:identifier>
 </oai_dc:dc>


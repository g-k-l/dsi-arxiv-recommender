<oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.openarchives.org/OAI/2.0/" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Bridge Correlational Neural Networks for Multilingual Multimodal
  Representation Learning</dc:title>
 <dc:creator>Rajendran, Janarthanan</dc:creator>
 <dc:creator>Khapra, Mitesh M.</dc:creator>
 <dc:creator>Chandar, Sarath</dc:creator>
 <dc:creator>Ravindran, Balaraman</dc:creator>
 <dc:subject>Computer Science - Computation and Language</dc:subject>
 <dc:description>  Recently there has been a lot of interest in learning common representations
for multiple views of data. Typically, such common representations are learned
using a parallel corpus between the two views (say, 1M images and their English
captions). In this work, we address a real-world scenario where no direct
parallel data is available between two views of interest (say, $V_1$ and $V_2$)
but parallel data is available between each of these views and a pivot view
($V_3$). We propose a model for learning a common representation for $V_1$,
$V_2$ and $V_3$ using only the parallel data available between $V_1V_3$ and
$V_2V_3$. The proposed model is generic and even works when there are $n$ views
of interest and only one pivot view which acts as a bridge between them. There
are two specific downstream applications that we focus on (i) transfer learning
between languages $L_1$,$L_2$,...,$L_n$ using a pivot language $L$ and (ii)
cross modal access between images and a language $L_1$ using a pivot language
$L_2$. Our model achieves state-of-the-art performance in multilingual document
classification on the publicly available multilingual TED corpus and promising
results in multilingual multimodal retrieval on a new dataset created and
released as a part of this work.
</dc:description>
 <dc:description>Comment: Published at NAACL-HLT 2016</dc:description>
 <dc:date>2015-10-12</dc:date>
 <dc:date>2016-07-01</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1510.03519</dc:identifier>
 </oai_dc:dc>


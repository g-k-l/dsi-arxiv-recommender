<oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.openarchives.org/OAI/2.0/" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd">
 <dc:title>Reviewer Integration and Performance Measurement for Malware Detection</dc:title>
 <dc:creator>Miller, Brad</dc:creator>
 <dc:creator>Kantchelian, Alex</dc:creator>
 <dc:creator>Tschantz, Michael Carl</dc:creator>
 <dc:creator>Afroz, Sadia</dc:creator>
 <dc:creator>Bachwani, Rekha</dc:creator>
 <dc:creator>Faizullabhoy, Riyaz</dc:creator>
 <dc:creator>Huang, Ling</dc:creator>
 <dc:creator>Shankar, Vaishaal</dc:creator>
 <dc:creator>Wu, Tony</dc:creator>
 <dc:creator>Yiu, George</dc:creator>
 <dc:creator>Joseph, Anthony D.</dc:creator>
 <dc:creator>Tygar, J. D.</dc:creator>
 <dc:subject>Computer Science - Cryptography and Security</dc:subject>
 <dc:description>  We present and evaluate a large-scale malware detection system integrating
machine learning with expert reviewers, treating reviewers as a limited
labeling resource. We demonstrate that even in small numbers, reviewers can
vastly improve the system's ability to keep pace with evolving threats. We
conduct our evaluation on a sample of VirusTotal submissions spanning 2.5 years
and containing 1.1 million binaries with 778GB of raw feature data. Without
reviewer assistance, we achieve 72% detection at a 0.5% false positive rate,
performing comparable to the best vendors on VirusTotal. Given a budget of 80
accurate reviews daily, we improve detection to 89% and are able to detect 42%
of malicious binaries undetected upon initial submission to VirusTotal.
Additionally, we identify a previously unnoticed temporal inconsistency in the
labeling of training datasets. We compare the impact of training labels
obtained at the same time training data is first seen with training labels
obtained months later. We find that using training labels obtained well after
samples appear, and thus unavailable in practice for current training data,
inflates measured detection by almost 20 percentage points. We release our
cluster-based implementation, as well as a list of all hashes in our evaluation
and 3% of our entire dataset.
</dc:description>
 <dc:description>Comment: 20 papers, 11 figures, accepted at the 13th Conference on Detection
  of Intrusions and Malware &amp; Vulnerability Assessment (DIMVA 2016)</dc:description>
 <dc:date>2015-10-25</dc:date>
 <dc:date>2016-05-26</dc:date>
 <dc:type>text</dc:type>
 <dc:identifier>http://arxiv.org/abs/1510.07338</dc:identifier>
 </oai_dc:dc>

